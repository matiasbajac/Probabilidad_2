---
title: "Entrega P2"
author: "Matias Bajac"
date: '2023-06-12'
output: pdf_document
header-incudes:
-  \usepackage{xcolor}
- \DeclareMathOperator{\E}{\mathbf{E}}
geometry: margin=1in
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ejercicio 3.84

Aplicamos  la **desigualdad de Jensen** , $\phi(\E(X)\leq\E\phi(X))$.

Tenemos que $\phi(x)$ es convexa ya que $\phi''(x)$ > 0

$$\E(\phi(x)) = \E(e^x) = \underbrace{\sum\limits_{m = 1}^{n}p(m)y_m}_{\substack{\text{Por definición}\\\text{de esperanza}}}$$ 
$$\phi(\E(X)=exp({\sum\limits_{m = 1}^{n}p(m)\log(y_m)})$$ 

$$\underbrace{\exp(\log\prod\limits_{m=1}^{n}y_m^{p(m)})}_{\substack{\text{Por propiedad}\\\text{de logaritmo}}} = {\prod\limits_{m=1}^{n}y_m^{p(m)})}$$

entonces por la desigualdad de Jensen podemos concluir que 
$$\exp{\E(X)}\leq\E(e^x)$$

# Ejercicio 4.5

##  Si $X_n \overset{L^2}{\rightarrow} X$  entonces $X_n \overset{P}{\rightarrow} X$ 


 Para todo $\epsilon>0$
 
$$  \Pr \big( |X_n - X| > \epsilon \big) =  \Pr \big( |X_n - X|^2 > \epsilon^2 \big) \leq \E \left( \frac{ (X_n-X)^2}{\epsilon^2} \right) \overset{n}{\rightarrow} 0$$
Usando la desigualdad de Chebyshev - Markov, queda probado que 
 Si $X_n \overset{L^2}{\rightarrow} X$ entonces $X_n \overset{p}{\rightarrow} X$.

- El recíproco no es cierto.








